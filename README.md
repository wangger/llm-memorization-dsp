# Unlocking Memorization in Large Language Models with Dynamic Soft Prompting

## Introduction
This repository contains the source code to extract memorized training data from large language models (LLMs) using dynamic soft prompting. The implementation is based on the repo (https://github.com/amazon-science/controlling-llm-memorization). 

<div align="center">
	<img src="./materials/Github_Image.png" alt="ali_pay" width="600" />
</div>

## Execution
It is coming soon.

## Citation
If you find the repo useful, please kindly star this repository and cite our papers:

```bibtex
@inproceedings{wang2024unlocking,
    title     = {Unlocking Memorization in Large Language Models with Dynamic Soft Prompting},
    author    = {Wang, Zhepeng and Bao, Runxue and Wu, Yawen and Taylor, Jackson and Xiao, Cao and Zheng, Feng and Jiang, Weiwen and Gao, Shangqian and Zhang, Yanfu},
    booktitle = {Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing},
    year      = {2024}
}
```